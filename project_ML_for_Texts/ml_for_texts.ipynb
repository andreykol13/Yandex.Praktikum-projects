{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект \"Токсичные комментарии\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
    "Нужно обучить модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок. Построить модель со значением метрики качества F1 не меньше 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## План выполнения проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [**Загрузите и подготовьте данные.**](#step1) Данные находятся в файле <i>/datasets/toxic_comments.csv</i>.\n",
    "1. [**Обучите разные модели.**](#step2)\n",
    "1. [**Сделайте выводы.**](#step3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `text` — текст комментария;\n",
    "- `toxic` — является ли комментарий токсичным, <i>целевой признак</i>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name='step1'></a>Шаг 1. Загрузите и подготовьте данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала сделаем импорт всех необходимых библиотек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/andreykol/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/andreykol/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer # лемматизатор английского, берущий по одному слову\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь загрузим данные, записав их в переменную `comm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    comm = pd.read_csv('/Users/andreykol/PycharmProjects/Yandex.Praktikum-projects/project_ML_for_Texts/toxic_comments.csv')\n",
    "    #comm = pd.read_csv('/datasets/toxic.csv')\n",
    "except:\n",
    "    print('Ошибка при загрузке файла!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кратко просмотрим имеющиеся данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n",
      "None\n",
      "Index(['text', 'toxic'], dtype='object')\n",
      "text     COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK\n",
      "toxic                                               1\n",
      "Name: 6, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(comm.info())\n",
    "print(comm.columns)\n",
    "print(comm.iloc[6, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Типы данных у нас в порядке, также мы вывели на экран один из оскорбительных комментариев, у него действительно в столбце `toxic` стоит значение `1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее проведем очистку и лемматизацию всех текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = comm['text'].values.astype('U') # создали корпус"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem = WordNetLemmatizer()\n",
    "clean_corpus = [] # получим очищенный текст\n",
    "for text in corpus:\n",
    "    text = re.sub(r'[^A-Za-z ]', ' ', text)\n",
    "    words = text.lower().split()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_words.append(lem.lemmatize(word)) # лемматизатор справляется плохо, но оставим его\n",
    "    text = \" \".join(new_words)\n",
    "    clean_corpus.append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь сравним тексты до и после обработки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "\n",
      "Not at all, you are making a straw man argument here. I never claimed O'Donohue had that position, rather that practitioners and researchers in the field ignored the DSM position, which is exactly what the quote says and also something O'Donohue agrees with. \n",
      "\n",
      "Again, I was combating the notion that it was a \"\"absurd part\"\" to claim that pedophilia is a sexual orientation. Since many researchers hold this position, it would be unfair to call it absurd. The disorder part is divided in the field, some argue that it is not a disorder at all, some do. At the end of the day, it is a value judgment (as Cantor pointed out earlier in the thread), not a scientific judgement. If we choose to make this value judgment in the article, it should be stated clearly and not pretend to have a scientific basis.   \"\n",
      "\n",
      "not at all you are making a straw man argument here i never claimed o donohue had that position rather that practitioner and researcher in the field ignored the dsm position which is exactly what the quote say and also something o donohue agrees with again i wa combating the notion that it wa a absurd part to claim that pedophilia is a sexual orientation since many researcher hold this position it would be unfair to call it absurd the disorder part is divided in the field some argue that it is not a disorder at all some do at the end of the day it is a value judgment a cantor pointed out earlier in the thread not a scientific judgement if we choose to make this value judgment in the article it should be stated clearly and not pretend to have a scientific basis\n"
     ]
    }
   ],
   "source": [
    "print(corpus[35])\n",
    "print()\n",
    "print(clean_corpus[35])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Странно, что такие слова как `divided` лемматизатор не обработал и не вернул форму `divide`. Итак, теперь сформируем данные для модели в будущем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "tfidf = TfidfVectorizer(stop_words=stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm['text'] = pd.DataFrame(data=clean_corpus)\n",
    "comm['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы наблюдаем дисбаланс классов, так что будем \"взвешивать\" классы при делении на выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, теперь пора разделить наши данные на обучающую, валидационную и тестовую выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nottest, test = train_test_split(comm, test_size=0.1, random_state=420, shuffle=True, stratify=comm['toxic'])\n",
    "train, valid = train_test_split(nottest, test_size=0.1111, random_state=420, shuffle=True, stratify=nottest['toxic'])\n",
    "# разбили на 80-10-10 процентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tfidf.fit_transform(train['text'])\n",
    "y_train = train['toxic']\n",
    "X_valid = tfidf.transform(valid['text'])\n",
    "y_valid = valid['toxic']\n",
    "X_test = tfidf.transform(test['text'])\n",
    "y_test = test['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, данные разделены, векторизованы и готовы применяться в различных моделях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name='step2'></a>Шаг 2. Обучите разные модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала обучим логистическую регрессию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1-score for logistic regression: 0.758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(class_weight='balanced')\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred = log_reg.predict(X_valid)\n",
    "print('Validation F1-score for logistic regression:', round(f1_score(y_valid, y_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Валидация показала, что метрика превысила 0.75. Теперь дадим пообучаться случайному лесу. Выберем определенные параметры для экономии времени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1-score for random forest: 0.232\n"
     ]
    }
   ],
   "source": [
    "myforest = RandomForestClassifier(n_estimators=100, max_depth=100, random_state=42)\n",
    "myforest.fit(X_train, y_train)\n",
    "y_pred = myforest.predict(X_valid)\n",
    "print('Validation F1-score for random forest:', round(f1_score(y_valid, y_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель обучалась несколько минут, но ее результаты крайне низкие. Мы не будем использовать случайный лес далее. После этого в проекте обучалась модель SVM, но была удалена из-за времени выполнения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь протестируем нашу лучшую модель (лог. регрессию) на новых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1-score for logistic regression: 0.754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X_nottest = tfidf.fit_transform(nottest['text']) # фиттим на большем количестве\n",
    "y_nottest = nottest['toxic']\n",
    "X_test = tfidf.transform(test['text'])\n",
    "y_test = test['toxic']\n",
    "log_reg.fit(X_nottest, y_nottest)\n",
    "y_pred = log_reg.predict(X_test)\n",
    "print('Test F1-score for logistic regression:', round(f1_score(y_test, y_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, на новых данных мы получили приемлемый результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name='step3'></a>Шаг 3. Сделайте выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, в этом проекте мы векторизовали наши сырые текстовые данные, перед этим лемматизировав и очистив их. Также мы проверили, какая из моделей лучше всего подходит для решения нашей задачи и, использовав ее, получили требуемый результат метрики F1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
